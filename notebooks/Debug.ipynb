{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discourse.models.debug as ddebug\n",
      "import discourse.data as data\n",
      "import discourse.hypergraph as hyper\n",
      "\n",
      "import pydecode.model as model\n",
      "from pystruct.learners import StructuredPerceptron\n",
      "\n",
      "import corenlp_xml as cnlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DiscourseSequenceModel(model.DynamicProgrammingModel):\n",
      "    def dynamic_program(self, discourse_model, c):\n",
      "        return hyper.build_hypergraph(discourse_model, c)\n",
      "    \n",
      "    def initialize_features(self, discourse_model):\n",
      "        return None\n",
      "    \n",
      "    def constraints(self, discourse_model, hypergraph):\n",
      "        nsents = len(discourse_model)\n",
      "        return cons.Constraints(hypergraph, [('sent-{}'.format(i), -1)\n",
      "                                             for i in range(nsents)]).build(hyper.build_constraints)\n",
      "    \n",
      "    def factored_psi(self, discourse_model, transition, data):\n",
      "        return discourse_model.feature_map(transition)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "dsm = DiscourseSequenceModel()\n",
      "sp = StructuredPerceptron(dsm, verbose=1, max_iter=25)\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "    \n",
      "print \"running perceptron\"    \n",
      "   \n",
      "    \n",
      "import warnings\n",
      "    \n",
      "with warnings.catch_warnings():\n",
      "    warnings.simplefilter('ignore')\n",
      "    sp.fit(dataX, dataY)\n",
      "    \n",
      "\n",
      "    \n",
      "    #print len(model)\n",
      "    \n",
      "    \n",
      "    #for s in doc:\n",
      "    #print doc[0]_s2i(self,s)\n",
      "    \n",
      "      \n",
      "#hypergraph = model.hypergraph()\n",
      "#import pydecode.display as display\n",
      "#display.HypergraphFormatter(hypergraph).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "running perceptron"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 0\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 1\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 2\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 3\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 4\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 5\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 6\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 7\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 8\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 9\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 10\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 11\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 12\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 13\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 14\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 15\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 16\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 17\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 18\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 19\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 20\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 21\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 22\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 23\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 24\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def weight_function(model):\n",
      "    def score_transition(transition):\n",
      "        fmap = model.feature_map(transition)\n",
      "        return fmap['GOLD']\n",
      "    return score_transition\n",
      "    \n",
      "import pydecode.hyper as ph\n",
      "weights = ph.Potentials(hypergraph).build(weight_function(model))\n",
      "path = ph.best_path(hypergraph, weights)\n",
      "edges = [hypergraph.label(edge) for edge in path]\n",
      "for e in edges:\n",
      "    print e\n",
      "#display.HypergraphPathFormatter(hypergraph, [path]).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "() -> () -> START -> sent-0\n",
        "() -> START -> sent-0 -> sent-1\n",
        "START -> sent-0 -> sent-1 -> sent-2\n",
        "sent-0 -> sent-1 -> sent-2 -> sent-3\n",
        "sent-1 -> sent-2 -> sent-3 -> sent-4\n",
        "sent-2 -> sent-3 -> sent-4 -> sent-5\n",
        "sent-5 -> END\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testX = []\n",
      "testY = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    model = ddebug.GoldModel(doc, history=2)\n",
      "    gold_trans = model.gold_transitions()\n",
      "    testX.append(model)\n",
      "    testY.append(gold_trans)\n",
      "\n",
      "sp.score(testX,testY)    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}