{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import discourse.models.debug as ddebug\n",
      "import discourse.data as data\n",
      "import discourse.inference.perceptron as perceptron\n",
      "from  discourse.models.rush import RushModel\n",
      "\n",
      "import corenlp_xml as cnlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "ptron = perceptron.PerceptronTrainer()\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "\n",
      "     \n",
      "print len(dataX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "54"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"running perceptron\"\n",
      "ptron.fit(dataX,dataY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running perceptron\n",
        "iteration 0\n",
        "avg loss: 0.005618 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 1\n",
        "avg loss: 0.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "Loss zero. Stopping.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"loading test data\"\n",
      "testX = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        testX.append(model)\n",
      "        \n",
      "\n",
      "print len(testX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading test data\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Predicting...\"\n",
      "predY = ptron.predict(testX)\n",
      "print \"done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting...\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import getenv\n",
      "from os.path import join\n",
      "\n",
      "pred_fname = '/tmp/predicted_file'\n",
      "pred_file = open(pred_fname, 'w')\n",
      "\n",
      "gold_fname = '/tmp/gold_file'\n",
      "gold_file = open(gold_fname, 'w')\n",
      "\n",
      "ddir = getenv(\"DISCOURSEDIR\",\".\")\n",
      "eval_script = join(ddir, \"eval\", \"ordering-eval.py\")\n",
      "\n",
      "for i, model in enumerate(testX):\n",
      "    pred_order = predY[i]\n",
      "    pred_str = model.ordering2str(pred_order)\n",
      "    \n",
      "    pred_file.write(pred_str.encode('utf-8')+\"\\n\\n\")\n",
      "    pred_file.flush()\n",
      "    \n",
      "    gold_str = model.gold_str()\n",
      "    gold_file.write(gold_str.encode('utf-8')+\"\\n\\n\")\n",
      "    gold_file.flush()\n",
      "\n",
      "pred_file.close()\n",
      "gold_file.close()\n",
      "\n",
      "!python $eval_script --gold $gold_fname --predicted $pred_fname       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total documents: 25\r\n",
        "Total correct: 25\r\n",
        "Accuracy: 1.0\r\n",
        "Avg. Kendall's Tau 1.0\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for y in predY:\n",
      "    for s in y:\n",
      "        print s\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "    \n",
      "print \"running perceptron\"    \n",
      "   \n",
      "    \n",
      "import warnings\n",
      "    \n",
      "with warnings.catch_warnings():\n",
      "    warnings.simplefilter('ignore')\n",
      "    sp.fit(dataX, dataY)\n",
      "    \n",
      "\n",
      "    \n",
      "    #print len(model)\n",
      "    \n",
      "    \n",
      "    #for s in doc:\n",
      "    #print doc[0]_s2i(self,s)\n",
      "    \n",
      "      \n",
      "#hypergraph = model.hypergraph()\n",
      "#import pydecode.display as display\n",
      "#display.HypergraphFormatter(hypergraph).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "running perceptron"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'sp' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-f8179112984b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'sp' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def weight_function(model):\n",
      "    def score_transition(transition):\n",
      "        fmap = model.feature_map(transition)\n",
      "        return fmap['GOLD']\n",
      "    return score_transition\n",
      "    \n",
      "import pydecode.hyper as ph\n",
      "weights = ph.Potentials(hypergraph).build(weight_function(model))\n",
      "path = ph.best_path(hypergraph, weights)\n",
      "edges = [hypergraph.label(edge) for edge in path]\n",
      "for e in edges:\n",
      "    print e\n",
      "#display.HypergraphPathFormatter(hypergraph, [path]).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "() -> () -> START -> sent-0\n",
        "() -> START -> sent-0 -> sent-1\n",
        "START -> sent-0 -> sent-1 -> sent-2\n",
        "sent-0 -> sent-1 -> sent-2 -> sent-3\n",
        "sent-1 -> sent-2 -> sent-3 -> sent-4\n",
        "sent-2 -> sent-3 -> sent-4 -> sent-5\n",
        "sent-5 -> END\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testX = []\n",
      "testY = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 6:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        testX.append(model)\n",
      "        testY.append(gold_trans)\n",
      "    \n",
      "\n",
      "print len(testX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = ptron.predict(testX)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'StructuredPerceptron' object has no attribute 'w'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-9cea5c412660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/chris/projects/discourse/latest/discourse/discourse/inference/perceptron.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, testX)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mpredY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mpredicted_sentence_orderings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrecover_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredicted_sentence_orderings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pystruct/learners/ssvm.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch_inference'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'StructuredPerceptron' object has no attribute 'w'"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for y in Y:\n",
      "    for p in y:\n",
      "        print p\n",
      "    print \n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sent-3 -> sent-4\n",
        "sent-4 -> END\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-1 -> sent-2\n",
        "sent-2 -> sent-3\n",
        "\n",
        "\n",
        "sent-2 -> sent-3\n",
        "sent-3 -> sent-4\n",
        "START -> sent-0\n",
        "sent-4 -> END\n",
        "sent-1 -> sent-2\n",
        "sent-0 -> sent-1\n",
        "\n",
        "\n",
        "sent-1 -> sent-2\n",
        "START -> sent-0\n",
        "sent-3 -> sent-4\n",
        "sent-0 -> sent-1\n",
        "sent-2 -> sent-3\n",
        "sent-4 -> END\n",
        "\n",
        "\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-4 -> END\n",
        "sent-2 -> sent-3\n",
        "sent-1 -> sent-2\n",
        "sent-3 -> sent-4\n",
        "\n",
        "\n",
        "sent-3 -> END\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-1 -> sent-2\n",
        "sent-2 -> sent-3\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord_trans = recover_order(Y[0])\n",
      "for t in ord_trans:\n",
      "    print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sent-0\n",
        "sent-1\n",
        "sent-2\n",
        "sent-3\n",
        "sent-4\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discourse.models.debug as ddebug\n",
      "import discourse.data as data\n",
      "import discourse.inference.perceptron as perceptron\n",
      "\n",
      "import corenlp_xml as cnlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "ptron = perceptron.PerceptronTrainer()\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"running perceptron\"\n",
      "ptron.fit(dataX,dataY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running perceptron\n",
        "iteration 0\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 1\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"loading test data\"\n",
      "testX = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        testX.append(model)\n",
      "        \n",
      "\n",
      "print len(testX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading test data\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Predicting...\"\n",
      "predY = ptron.predict(testX)\n",
      "print \"done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting...\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import getenv\n",
      "from os.path import join\n",
      "\n",
      "pred_fname = '/tmp/predicted_file'\n",
      "pred_file = open(pred_fname, 'w')\n",
      "\n",
      "gold_fname = '/tmp/gold_file'\n",
      "gold_file = open(gold_fname, 'w')\n",
      "\n",
      "ddir = getenv(\"DISCOURSEDIR\",\".\")\n",
      "eval_script = join(ddir, \"eval\", \"ordering-eval.py\")\n",
      "\n",
      "for i, model in enumerate(testX):\n",
      "    pred_order = predY[i]\n",
      "    pred_str = model.ordering2str(pred_order)\n",
      "    \n",
      "    pred_file.write(pred_str.encode('utf-8')+\"\\n\\n\")\n",
      "    pred_file.flush()\n",
      "    \n",
      "    gold_str = model.gold_str()\n",
      "    gold_file.write(gold_str.encode('utf-8')+\"\\n\\n\")\n",
      "    gold_file.flush()\n",
      "\n",
      "pred_file.close()\n",
      "gold_file.close()\n",
      "\n",
      "!python $eval_script --gold $gold_fname --predicted $pred_fname       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total documents: 25\r\n",
        "Total correct: 25\r\n",
        "Accuracy: 1.0\r\n",
        "Avg. Kendall's Tau 1.0\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}