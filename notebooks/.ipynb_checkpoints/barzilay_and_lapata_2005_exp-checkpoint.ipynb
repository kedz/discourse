{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discourse.data as dd\n",
      "from discourse.inference import svm as disvm\n",
      "from discourse.models import barzilay as dmb\n",
      "from discourse.models import entity_grid as eg\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Entity Grid Coherence experiments (Barzilay & Lapata, 2005)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NTSB CORPUS"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training (SVM Rank)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SVM Rank model from svmlight.\n",
      "trainer = disvm.RankSVMTrainer()\n",
      "\n",
      "# Counter for the total number of coherent/incoherent training pairs.\n",
      "total_training = 0\n",
      "\n",
      "# Read in grid models from the corpus:\n",
      "for original_grid, perms in dd.ntsb_barzilay_grids_train():\n",
      "\n",
      "    # The model for the original human ordering.\n",
      "    model = eg.new_entity_grid(open(original_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "\n",
      "    # The set of less coherent random permutation models: at most 20 for each example.\n",
      "    pmodels = []\n",
      "    for perm_grid in perms:\n",
      "        perm_model = eg.new_entity_grid(open(perm_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "        pmodels.append(perm_model)\n",
      "\n",
      "    # There are some blank documents in this corpus(???) - empty is True if the grid is blank.\n",
      "    # We skip these examples.    \n",
      "    empty = True\n",
      "    for grid in model.grids:\n",
      "        if grid.shape[1] > 0:\n",
      "            empty = False\n",
      "    if not empty:\n",
      "        total_training += len(pmodels)\n",
      "        trainer.add_model(model, permutations=pmodels)\n",
      "    else:\n",
      "        print original_grid\n",
      "\n",
      "print \"Total NTSB training pairs: {}\".format(total_training)\n",
      "trainer.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total NTSB training pairs: 2000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The set of learned model weights.\n",
      "weights = trainer.weights\n",
      "\n",
      "# Number of times the coherent model is ranked higher than an incoherent model.\n",
      "num_correct = 0\n",
      "\n",
      "# Total experiments performed.\n",
      "total_experiments = 0\n",
      "\n",
      "# Read in grid models from the corpus: \n",
      "for original_grid, perms in dd.ntsb_barzilay_grids_test():\n",
      "\n",
      "    # The model for the original human ordering.     \n",
      "    model = eg.new_entity_grid(open(original_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "\n",
      "    # The set of less coherent random permutation models: at most 20 for each example.\n",
      "    pmodels = []\n",
      "    for perm_grid in perms:\n",
      "        perm_model = eg.new_entity_grid(open(perm_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "        pmodels.append(perm_model)\n",
      "\n",
      "    # There are some blank documents in this corpus(???) - empty is True if the grid is blank.\n",
      "    # We skip these examples.\n",
      "    empty = True\n",
      "    for grid in model.grids:\n",
      "        if grid.shape[1] > 0:\n",
      "            empty = False\n",
      "    if not empty:\n",
      "        for pmodel in pmodels:\n",
      "            total_experiments += 1\n",
      "            \n",
      "            # Compare model weights for the coherent example and the incoherent example.\n",
      "            if np.dot(weights, model.get_trans_prob_vctr()) > np.dot(weights, pmodel.get_trans_prob_vctr()):\n",
      "                num_correct += 1\n",
      "\n",
      "    else:\n",
      "        print original_grid\n",
      "\n",
      "print \"Total: {}\\nAcc: {}\".format(total_experiments, num_correct/float(total_experiments))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 21.05973913 -41.20501801  16.53128664  14.744363     5.5398188    0.           0.\n",
        "   0.          19.50604462   0.           0.           0.         -36.17622999\n",
        "   0.           0.           0.          -8.90539043 -63.36380759\n",
        " -10.26730942  -5.78435143 -16.82680557 -22.28542312  65.7063412\n",
        "  33.44557519   4.11226196 -36.70422918  22.9553209   38.11760635\n",
        "  -4.69530934 -40.02028351  23.96575996  20.54994518]\n",
        "Total: 2000\n",
        "Acc: 0.899"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "APWS CORPUS"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training (SVM Rank)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SVM Rank model from svmlight.\n",
      "trainer = disvm.RankSVMTrainer()\n",
      "\n",
      "# Counter for the total number of coherent/incoherent training pairs.\n",
      "total_training = 0\n",
      "\n",
      "# Read in grid models from the corpus:\n",
      "for original_grid, perms in dd.apws_barzilay_grids_train():\n",
      "\n",
      "    # The model for the original human ordering.\n",
      "    model = eg.new_entity_grid(open(original_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "\n",
      "    # The set of less coherent random permutation models: at most 20 for each example.\n",
      "    pmodels = []\n",
      "    for perm_grid in perms:\n",
      "        perm_model = eg.new_entity_grid(open(perm_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "        pmodels.append(perm_model)\n",
      "\n",
      "    # There are some blank documents in this corpus(???) - empty is True if the grid is blank.\n",
      "    # We skip these examples.    \n",
      "    empty = True\n",
      "    for grid in model.grids:\n",
      "        if grid.shape[1] > 0:\n",
      "            empty = False\n",
      "    if not empty:\n",
      "        total_training += len(pmodels)\n",
      "        trainer.add_model(model, permutations=pmodels)\n",
      "    else:\n",
      "        print original_grid\n",
      "\n",
      "print \"Total APWS training pairs: {}\".format(total_training)\n",
      "trainer.train()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/chris/projects/sasha/branches/gb/discourse/data/barzilay/grids/train/apws/apwsE951018.0070-2-2-0.perm-1-p.parsed.grid\n",
        "/home/chris/projects/sasha/branches/gb/discourse/data/barzilay/grids/train/apws/apwsE951018.0170-2-2-0.perm-1-p.parsed.grid\n",
        "/home/chris/projects/sasha/branches/gb/discourse/data/barzilay/grids/train/apws/apwsE951018.0182-2-2-0.perm-1-p.parsed.grid\n",
        "/home/chris/projects/sasha/branches/gb/discourse/data/barzilay/grids/train/apws/apwsE951020.0430-2-2-0.perm-1-p.parsed.grid"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total APWS training pairs: 1858"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The set of learned model weights.\n",
      "weights = trainer.weights\n",
      "\n",
      "# Number of times the coherent model is ranked higher than an incoherent model.\n",
      "num_correct = 0\n",
      "\n",
      "# Total experiments performed.\n",
      "total_experiments = 0\n",
      "\n",
      "# Read in grid models from the corpus: \n",
      "for original_grid, perms in dd.apws_barzilay_grids_test():\n",
      "\n",
      "    # The model for the original human ordering.     \n",
      "    model = eg.new_entity_grid(open(original_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "\n",
      "    # The set of less coherent random permutation models: at most 20 for each example.\n",
      "    pmodels = []\n",
      "    for perm_grid in perms:\n",
      "        perm_model = eg.new_entity_grid(open(perm_grid, 'r'), syntax=True, max_salience=2, history=2)\n",
      "        pmodels.append(perm_model)\n",
      "\n",
      "    # There are some blank documents in this corpus(???) - empty is True if the grid is blank.\n",
      "    # We skip these examples.\n",
      "    empty = True\n",
      "    for grid in model.grids:\n",
      "        if grid.shape[1] > 0:\n",
      "            empty = False\n",
      "    if not empty:\n",
      "        for pmodel in pmodels:\n",
      "            total_experiments += 1\n",
      "            \n",
      "            # Compare model weights for the coherent example and the incoherent example.\n",
      "            if np.dot(weights, model.get_trans_prob_vctr()) > np.dot(weights, pmodel.get_trans_prob_vctr()):\n",
      "                num_correct += 1\n",
      "\n",
      "    else:\n",
      "        print original_grid\n",
      "\n",
      "print \"Total: {}\\nAcc: {}\".format(total_experiments, num_correct/float(total_experiments))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total: 1978\n",
        "Acc: 0.7108190091\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}