{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discourse.models.debug as ddebug\n",
      "import discourse.data as data\n",
      "import discourse.hypergraph as hyper\n",
      "\n",
      "import corenlp_xml as cnlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "    \n",
      "print \"running perceptron\"    \n",
      "   \n",
      "    \n",
      "import warnings\n",
      "    \n",
      "with warnings.catch_warnings():\n",
      "    warnings.simplefilter('ignore')\n",
      "    sp.fit(dataX, dataY)\n",
      "    \n",
      "\n",
      "    \n",
      "    #print len(model)\n",
      "    \n",
      "    \n",
      "    #for s in doc:\n",
      "    #print doc[0]_s2i(self,s)\n",
      "    \n",
      "      \n",
      "#hypergraph = model.hypergraph()\n",
      "#import pydecode.display as display\n",
      "#display.HypergraphFormatter(hypergraph).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "running perceptron"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 0\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 1\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 2\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 3\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 4\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 5\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 6\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 7\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 8\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 9\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 10\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 11\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 12\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 13\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 14\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 15\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 16\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 17\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 18\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 19\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 20\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 21\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 22\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 23\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 24\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def weight_function(model):\n",
      "    def score_transition(transition):\n",
      "        fmap = model.feature_map(transition)\n",
      "        return fmap['GOLD']\n",
      "    return score_transition\n",
      "    \n",
      "import pydecode.hyper as ph\n",
      "weights = ph.Potentials(hypergraph).build(weight_function(model))\n",
      "path = ph.best_path(hypergraph, weights)\n",
      "edges = [hypergraph.label(edge) for edge in path]\n",
      "for e in edges:\n",
      "    print e\n",
      "#display.HypergraphPathFormatter(hypergraph, [path]).to_ipython()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "() -> () -> START -> sent-0\n",
        "() -> START -> sent-0 -> sent-1\n",
        "START -> sent-0 -> sent-1 -> sent-2\n",
        "sent-0 -> sent-1 -> sent-2 -> sent-3\n",
        "sent-1 -> sent-2 -> sent-3 -> sent-4\n",
        "sent-2 -> sent-3 -> sent-4 -> sent-5\n",
        "sent-5 -> END\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testX = []\n",
      "testY = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 6:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        testX.append(model)\n",
      "        testY.append(gold_trans)\n",
      "    \n",
      "\n",
      "print len(testX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = sp.predict(testX)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for y in Y:\n",
      "    for p in y:\n",
      "        print p\n",
      "    print \n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sent-3 -> sent-4\n",
        "sent-4 -> END\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-1 -> sent-2\n",
        "sent-2 -> sent-3\n",
        "\n",
        "\n",
        "sent-2 -> sent-3\n",
        "sent-3 -> sent-4\n",
        "START -> sent-0\n",
        "sent-4 -> END\n",
        "sent-1 -> sent-2\n",
        "sent-0 -> sent-1\n",
        "\n",
        "\n",
        "sent-1 -> sent-2\n",
        "START -> sent-0\n",
        "sent-3 -> sent-4\n",
        "sent-0 -> sent-1\n",
        "sent-2 -> sent-3\n",
        "sent-4 -> END\n",
        "\n",
        "\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-4 -> END\n",
        "sent-2 -> sent-3\n",
        "sent-1 -> sent-2\n",
        "sent-3 -> sent-4\n",
        "\n",
        "\n",
        "sent-3 -> END\n",
        "sent-0 -> sent-1\n",
        "START -> sent-0\n",
        "sent-1 -> sent-2\n",
        "sent-2 -> sent-3\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord_trans = recover_order(Y[0])\n",
      "for t in ord_trans:\n",
      "    print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sent-0\n",
        "sent-1\n",
        "sent-2\n",
        "sent-3\n",
        "sent-4\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discourse.models.debug as ddebug\n",
      "import discourse.data as data\n",
      "import discourse.inference.perceptron as perceptron\n",
      "\n",
      "import corenlp_xml as cnlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "ptron = perceptron.PerceptronTrainer()\n",
      "\n",
      "print \"loading data\"\n",
      "\n",
      "for xml in data.corenlp_apws_train():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        gold_trans = model.gold_transitions()\n",
      "        dataX.append(model)\n",
      "        dataY.append(gold_trans)\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"running perceptron\"\n",
      "ptron.fit(dataX,dataY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running perceptron\n",
        "iteration 0\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n",
        "iteration 1\n",
        "avg loss: 1.000000 w: [[ 5.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "effective learning rate: 1.000000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"loading test data\"\n",
      "testX = []\n",
      "\n",
      "for xml in data.corenlp_apws_test():\n",
      "    doc = cnlp.Document(xml)\n",
      "    if len(doc) < 8:\n",
      "        model = ddebug.GoldModel(doc, history=2)\n",
      "        testX.append(model)\n",
      "        \n",
      "\n",
      "print len(testX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading test data\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Predicting...\"\n",
      "predY = ptron.predict(testX)\n",
      "print \"done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting...\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import getenv\n",
      "from os.path import join\n",
      "\n",
      "pred_fname = '/tmp/predicted_file'\n",
      "pred_file = open(pred_fname, 'w')\n",
      "\n",
      "gold_fname = '/tmp/gold_file'\n",
      "gold_file = open(gold_fname, 'w')\n",
      "\n",
      "ddir = getenv(\"DISCOURSEDIR\",\".\")\n",
      "eval_script = join(ddir, \"eval\", \"ordering-eval.py\")\n",
      "\n",
      "for i, model in enumerate(testX):\n",
      "    pred_order = predY[i]\n",
      "    pred_str = model.ordering2str(pred_order)\n",
      "    \n",
      "    pred_file.write(pred_str.encode('utf-8')+\"\\n\\n\")\n",
      "    pred_file.flush()\n",
      "    \n",
      "    gold_str = model.gold_str()\n",
      "    gold_file.write(gold_str.encode('utf-8')+\"\\n\\n\")\n",
      "    gold_file.flush()\n",
      "\n",
      "pred_file.close()\n",
      "gold_file.close()\n",
      "\n",
      "!python $eval_script --gold $gold_fname --predicted $pred_fname       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total documents: 25\r\n",
        "Total correct: 25\r\n",
        "Accuracy: 1.0\r\n",
        "Avg. Kendall's Tau 1.0\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}