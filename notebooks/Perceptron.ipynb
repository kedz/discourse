{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pydecode.hyper as ph\n",
      "import pydecode.chart as chart\n",
      "import itertools\n",
      "from collections import namedtuple\n",
      "import pydecode.model as model\n",
      "import discourse.models.rush as dmr\n",
      "import discourse.data as dd\n",
      "from pystruct.learners import StructuredPerceptron"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Sentence(namedtuple(\"Sentence\", [\"label\", \"prev_sents\", \"pos\"])):\n",
      "\n",
      "    def __new__(_cls, label, prev_sents, pos):\n",
      "        non_nulls = [x for x in prev_sents if x != ()]\n",
      "\n",
      "        return super(_cls, Sentence).__new__(_cls, label, tuple(non_nulls), pos)\n",
      "\n",
      "    def __str__(self):\n",
      "        return \"{}: {}\".format(self.pos, self.label)\n",
      "\n",
      "class Transition(namedtuple(\"Transition\", ['sents'])):\n",
      "    def __str__(self):\n",
      "        label = ''\n",
      "        if len(self.sents) > 1:\n",
      "            for sent in self.sents[1:]:\n",
      "                label = \"{} -> \".format(sent) + label\n",
      "        return label + \"{}\".format(self.sents[0])\n",
      "\n",
      "\n",
      "def build_hypergraph(discourse_model, c):\n",
      "\n",
      "    node_labels = ['Sent_'+str(i) for i in range(1,discourse_model.num_sents+1)]\n",
      "    history_size = discourse_model.history_size\n",
      "    n = len(node_labels) + 1\n",
      "\n",
      "    hist_nodes = [node_labels, ['START',],] + [[()]] * (history_size-1)\n",
      "    start_sent = Sentence('START', (), 0)\n",
      "        \n",
      "    \n",
      "    c.init(start_sent)\n",
      "\n",
      "\n",
      "    for i in range(1,n):\n",
      "    \n",
      "        for labels in itertools.product(*hist_nodes[:-1]):\n",
      "    \n",
      "            c[Sentence(labels[0], (labels[1:]), i)] = \\\n",
      "                    c.sum([c[key] * c.sr(Transition(labels))\n",
      "                           for label3 in hist_nodes[-1]\n",
      "                           for key in [Sentence(labels[1], labels[2:]+tuple([label3]), i-1)]\n",
      "                           if key in c])\n",
      "                       \n",
      "        if i <= history_size:\n",
      "    \n",
      "            hist_nodes.pop(-1)\n",
      "            hist_nodes = [node_labels,] + hist_nodes\n",
      "\n",
      "\n",
      "    c[Sentence('END', (), n)] = \\\n",
      "            c.sum([c[key] * c.sr(Transition(('END', labels[0])))\n",
      "                   for labels in itertools.product(*hist_nodes[:-1])\n",
      "                   for key in [Sentence(labels[0], (labels[1:]), n-1)]\n",
      "                   if key in c])\n",
      "\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import pydecode.constraints as cons\n",
      "\n",
      "def cons_name(sent): return \"Sent_%s\"%(sent)\n",
      "\n",
      "def build_constraints(transition):\n",
      "    if transition.sents[0] not in ['START', 'END']:\n",
      "        return [(transition.sents[0], 1)]\n",
      "    return []\n",
      "\n",
      "class DiscourseSequenceModel(model.DynamicProgrammingModel):\n",
      "    def dynamic_program(self, discourse_model, c):\n",
      "        return build_hypergraph(discourse_model, c)\n",
      "    \n",
      "    def initialize_features(self, discourse_model):\n",
      "        return None\n",
      "    \n",
      "    def constraints(self, discourse_model, hypergraph):\n",
      "        return cons.Constraints(hypergraph, [(cons_name(sent), -1)\n",
      "                                             for sent in range(1,len(discourse_model.sentences)+1)]).build(\n",
      "                                      build_constraints)\n",
      "\n",
      "    \n",
      "    def factored_psi(self, discourse_model, transition, data):\n",
      "        return discourse_model.get_feature_map(transition)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataX = []\n",
      "dataY = []\n",
      "dsm = DiscourseSequenceModel()\n",
      "sp = StructuredPerceptron(dsm, verbose=1, max_iter=25)\n",
      "print \"loading data\"\n",
      "for train_xml_file in dd.corenlp_apws_train():\n",
      "    discourse_model = dmr.make_from_corenlp_xml(train_xml_file, history_size=2)\n",
      "    dataX.append(discourse_model)\n",
      "    dataY.append([Transition(['Sent_{}'.format(i), 'Sent_{}'.format(i+1)]) for i in range(1, discourse_model.num_sents)])\n",
      "\n",
      "print \"running perceptron\"    \n",
      "   \n",
      "    \n",
      "import warnings\n",
      "    \n",
      "with warnings.catch_warnings():\n",
      "    warnings.simplefilter('ignore')\n",
      "    sp.fit(dataX, dataY)\n",
      "    \n",
      "    \n",
      "    #dataY should be a list of edge labels.\n",
      "    \n",
      "    \n",
      "# avg loss should go down!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "running perceptron"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/projects/corenlp-xml-reader/python/corenlp_xml.py:11: FutureWarning: This search is broken in 1.3 and earlier, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/sentences/sentence'\n",
        "  sentences = tree.findall('//sentences/sentence')\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}